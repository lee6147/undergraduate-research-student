# 설명서

## 이 프로젝트는 뭔가?

VQC(Variational Quantum Classifier)와 QSVC(Quantum SVM)를 고전 머신러닝 모델(SVM, MLP, Random Forest)과 비교하는 양자 머신러닝 벤치마크 연구 프로젝트다. Iris, Wine, Breast Cancer 3개 데이터셋에서 7개 실험을 수행하고, 결과를 논문(LaTeX)으로 정리한다.

**핵심 발견:** VQC는 회로 깊이를 최대 4 reps까지 늘려도 고전 모델(95%+) 대비 유의하게 낮지만(Wilcoxon, p < 0.005), 동일한 양자 인코딩을 사용하는 QSVC는 고전 SVM과 동등한 성능을 달성한다. → 성능 병목은 양자 특징 공간이 아닌 변분 최적화에 있다.

---

## 읽는 순서

### 1단계: 핵심 소스코드 (`src/`)

| 순서 | 파일 | 설명 |
|------|------|------|
| 1 | `src/data_loader.py` | 데이터 로딩, StandardScaler→PCA→MinMaxScaler[0,π], 층화 분할 |
| 2 | `src/vqc_model.py` | VQC 학습 — feature map(angle/zz), ansatz(RA/ESU2), COBYLA/SPSA, algorithm_globals 시드 |
| 3 | `src/classical_models.py` | 고전 모델(SVM, MLP, RF) 학습 — 비교 기준선 |
| 4 | `src/stats_utils.py` | 통계 검정 유틸리티 (Wilcoxon signed-rank test, paired t-test) |

### 2단계: 실험 스크립트

| 순서 | 파일 | 실험 내용 |
|------|------|----------|
| 5 | `run_experiments_final.py` | 실험 1~4 (모델비교, 데이터크기, 옵티마이저, 회로깊이) — 10시드, Iris+BC |
| 6 | `run_experiment5_noise_final.py` | 실험 5: 양자 노이즈 영향 (탈분극 에러율별, Iris+BC) |
| 7 | `run_experiment6_convergence.py` | 실험 6: 수렴 분석 (maxiter별 loss curve, Iris+BC) |
| 8 | `run_experiment7_qsvc.py` | 실험 7: QSVC 양자 커널 SVM (3 데이터셋) |

### 3단계: 결과 확인

| 순서 | 파일 | 설명 |
|------|------|------|
| 9 | `results/` 폴더 | 7개 실험의 CSV 결과 + 통계 검정 결과 + loss curve JSON |
| 10 | `generate_figures.py` | CSV → 9개 논문용 그래프(PNG/PDF), 듀얼 데이터셋 서브플롯 지원 |
| 11 | `figures/` 폴더 | 생성된 그래프 이미지 (9개 × PNG+PDF) |

### 4단계: 논문

| 순서 | 파일 | 설명 |
|------|------|------|
| 12 | `paper.md` | 논문 마크다운 버전 (빠르게 읽기 좋음) |
| 13 | `paper.tex` | LaTeX 소스 (IEEE 형식, XeLaTeX+kotex, 참고문헌 20개) |
| 14 | `paper.pdf` | 빌드된 최종 논문 PDF (7페이지) |

### 5단계: 검증/테스트

| 순서 | 파일 | 설명 |
|------|------|------|
| 15 | `verify_tables.py` | CSV 수치 ↔ paper.tex 표 일치 검증 (7개 표, 228개 값) |
| 16 | `tests/` 폴더 | 8개 페이즈별 단위 테스트 |
| 17 | `run_tests_dispatch.py` | 전체 테스트를 페이즈별로 독립 실행 |

---

## 프로젝트 구조

```
vqc-benchmark/
├── src/                          # 핵심 소스코드
│   ├── data_loader.py            #   StandardScaler→PCA→MinMaxScaler[0,π]
│   ├── vqc_model.py              #   VQC 양자 회로 모델 (algorithm_globals 시드)
│   ├── classical_models.py       #   고전 ML 비교 모델
│   └── stats_utils.py            #   Wilcoxon/t-test 통계 검정
│
├── run_experiments_final.py      # 실험 1~4 실행 (10시드, 듀얼 데이터셋)
├── run_experiment5_noise_final.py# 실험 5: 노이즈 (10시드, Iris+BC)
├── run_experiment6_convergence.py# 실험 6: 수렴 (10시드, Iris+BC)
├── run_experiment7_qsvc.py       # 실험 7: QSVC (10시드, 3 데이터셋)
│
├── results/                      # 실험 결과
│   ├── experiment1_model_comparison.csv  # 8모델 × 3데이터셋
│   ├── experiment1_stats.csv             # Wilcoxon p-values
│   ├── experiment2_data_size.csv         # 5비율 × 4모델 × 2데이터셋
│   ├── experiment3_optimizer.csv         # 2옵티마이저 × 2데이터셋
│   ├── experiment4_circuit_depth.csv     # 4reps × 2데이터셋
│   ├── experiment5_noise.csv             # 5에러율 × 2데이터셋
│   ├── experiment6_convergence.csv       # 3maxiter × 2데이터셋
│   ├── experiment6_loss_curves.json      # 수렴 곡선 데이터
│   └── experiment7_qsvc.csv             # 2인코딩 × 3데이터셋
│
├── generate_figures.py           # 그래프 생성 (듀얼 서브플롯)
├── figures/                      # 논문용 그래프 (9개 PNG+PDF)
│
├── paper.tex                     # 논문 LaTeX 소스 (IEEE, 20 references)
├── paper.md                      # 논문 마크다운 버전
├── paper.pdf                     # 최종 논문 PDF (7페이지)
│
├── verify_tables.py              # 표 수치 검증 (228개 값)
├── tests/                        # 8개 페이즈 단위 테스트
├── run_tests_dispatch.py         # 테스트 독립 실행기
└── requirements.txt              # 의존성 목록
```

---

## 7개 실험 요약

| # | 실험 | 무엇을 비교? | 데이터셋 | 결과 행수 |
|---|------|-------------|---------|----------|
| 1 | 모델 비교 | 8개 모델 (SVM, MLP, RF, VQC×5) | Iris, Wine, BC | 24행 |
| 2 | 데이터 크기 | 학습 데이터 비율 (20%~100%) | Iris, BC | 40행 |
| 3 | 옵티마이저 | COBYLA vs SPSA | Iris, BC | 4행 |
| 4 | 회로 깊이 | reps=1,2,3,4 | Iris, BC | 8행 |
| 5 | 노이즈 | 탈분극 에러율 0~5% | Iris, BC | 10행 |
| 6 | 수렴 | maxiter=200,500,1000 | Iris, BC | 6행 |
| 7 | QSVC | 양자 커널 SVM (angle/zz) | Iris, Wine, BC | 6행 |

10개 랜덤 시드: [0, 1, 7, 13, 21, 42, 77, 99, 123, 456]
총 98행 집계 결과 (10시드 평균±표준편차)

---

## 전처리 파이프라인

```
원본 데이터 (Iris 4차원, Wine 13차원, BC 30차원)
        │
        ▼
  StandardScaler (평균=0, 표준편차=1)  ← PCA 전 정규화
        │
        ▼
  PCA (4차원으로 축소)                 ← Wine, BC만 해당
        │
        ▼
  MinMaxScaler [0, π]                 ← 양자 인코딩용 스케일링
        │
        ▼
  train/test 분할 (80:20, 층화 추출)
```

핵심: fit은 학습 데이터에서만, transform은 학습+테스트 → 데이터 누출 방지

---

## 데이터 흐름

```
데이터셋 (Iris, Wine, Breast Cancer)
        │
        ▼
  data_loader.py — StandardScaler→PCA→MinMaxScaler[0,π], 층화분할
        │
        ▼
  실험 스크립트 — VQC / Classical / QSVC 학습 (10시드 반복)
        │
        ├──→ results/*.csv — 정확도, F1, 학습시간 (mean±std)
        │
        ├──→ stats_utils.py — Wilcoxon signed-rank test (p-values)
        │
        ▼
  generate_figures.py → figures/*.png (듀얼 데이터셋 서브플롯)
        │
        ▼
  paper.tex → xelatex → paper.pdf
        │
        ▼
  verify_tables.py — CSV ↔ paper.tex 수치 일치 검증 (228개 값)
```

---

## 주요 연구 결론

1. **VQC < 고전 모델**: VQC는 reps=4까지 늘려도 Iris 66.7%, BC 87.8%에 머물러 고전 모델(95%+) 대비 통계적으로 유의하게 낮다 (Wilcoxon, p < 0.005)
2. **QSVC ≈ 고전 SVM**: QSVC-Angle은 BC에서 95.4±1.3%로 고전 SVM(95.2±1.7%)과 동등 → 양자 특징 공간은 유효하나 변분 최적화가 병목
3. **조기 수렴**: COBYLA는 maxiter와 무관하게 ~74-86회 함수 평가 후 수렴 포화. maxiter를 1000으로 늘려도 오히려 소폭 하락
4. **노이즈 영향**: 높은 노이즈(p=0.05)에서 Iris 8%p, BC 5%p 성능 하락. 중간 수준에서는 표준편차 내 변동
5. **이진 > 다중분류**: VQC는 BC(이진분류, 86.6%)에서 Iris/Wine(다중분류, 64-67%) 대비 현저히 우수
6. **Angle > ZZ**: Angle Encoding이 ZZ Feature Map보다 VQC, QSVC 모두에서 안정적

---

## 빠르게 실행해보기

```bash
# 의존성 설치
pip install -r requirements.txt

# 단위 테스트 전체 실행 (8개 페이즈)
python run_tests_dispatch.py

# 특정 페이즈만 테스트
python run_tests_dispatch.py 3    # Phase 3: VQC Training

# 그래프 재생성
python generate_figures.py

# 표 수치 검증 (7개 표, 228개 값)
python verify_tables.py

# 논문 PDF 빌드
xelatex paper.tex && xelatex paper.tex
```
